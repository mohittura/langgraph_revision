{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeecaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dc2d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c25483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groq_llm():\n",
    "    return ChatOpenAI(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        base_url=\"https://api.groq.com/openai/v1\",\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        temperature=0.7, max_tokens=2000\n",
    "    )\n",
    "llm = get_groq_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62163d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explaination: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "781ddf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "    prompt = f'generate a joke on the topic {state[\"topic\"]}, dont generate why did.. what does.. type set up jokes'\n",
    "    response = llm.invoke(prompt).content\n",
    "    return {'joke': response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff60bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explaination(state: JokeState):\n",
    "    prompt = f'generate an explaination on the joke {state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "    return {'explaination': response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46a5992e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x748e344d56a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke', generate_joke)\n",
    "graph.add_node('generate_explaination', generate_explaination)\n",
    "\n",
    "graph.add_edge(START, 'generate_joke')\n",
    "graph.add_edge('generate_joke', 'generate_explaination')\n",
    "graph.add_edge('generate_explaination', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09335153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'explaination': '**What the joke is doing**\\n'\n",
      "                 '\\n'\n",
      "                 '- **Setup:** “Large language models are so good at answering '\n",
      "                 'questions …”  \\n'\n",
      "                 '  This tells the listener that the AI will give a perfect, '\n",
      "                 'thorough answer.\\n'\n",
      "                 '\\n'\n",
      "                 '- **Punchline (the twist):** “…when you ask them for a joke, '\n",
      "                 'they keep rewriting the punchline until it becomes a '\n",
      "                 'novella.”  \\n'\n",
      "                 '  The expectation is a quick, one‑line punchline. Instead, '\n",
      "                 'the AI “rewrites” it over and over, turning a simple joke '\n",
      "                 'into a long, detailed story—literally a novella.\\n'\n",
      "                 '\\n'\n",
      "                 '**Why that’s funny**\\n'\n",
      "                 '\\n'\n",
      "                 '| Humor device | How it shows up in the joke |\\n'\n",
      "                 '|---------------|-----------------------------|\\n'\n",
      "                 '| **Incongruity** | A punchline is supposed to be short; the '\n",
      "                 'AI turns it into a long novel. |\\n'\n",
      "                 '| **Exaggeration** | The AI’s rewriting is taken to the '\n",
      "                 'extreme—so long it’s a novella. |\\n'\n",
      "                 '| **Meta‑humor** | The joke itself is about the process of '\n",
      "                 'making jokes, and it comments on the AI’s own behavior. |\\n'\n",
      "                 '| **Self‑referentiality** | The punchline is a “punchline” '\n",
      "                 'that is being rewritten, so the joke talks about itself. |\\n'\n",
      "                 '| **Commentary on AI** | It pokes fun at how LLMs can '\n",
      "                 'over‑explain or generate overly verbose responses. |\\n'\n",
      "                 '\\n'\n",
      "                 '**What’s happening in the story of the joke**\\n'\n",
      "                 '\\n'\n",
      "                 '1. **You ask the LLM for a joke.**  \\n'\n",
      "                 '   The LLM starts with a standard, concise answer.\\n'\n",
      "                 '\\n'\n",
      "                 '2. **The LLM “rewrites” the punchline.**  \\n'\n",
      "                 '   It refines, elaborates, adds details—just like an editor '\n",
      "                 'polishing a manuscript.\\n'\n",
      "                 '\\n'\n",
      "                 '3. **The process repeats.**  \\n'\n",
      "                 '   Each rewrite adds more depth, turning the one‑liner into '\n",
      "                 'a narrative arc.\\n'\n",
      "                 '\\n'\n",
      "                 '4. **Result:** a “novella” – a story that’s 20–40\\u202fk '\n",
      "                 'words long, far beyond what a joke needs.\\n'\n",
      "                 '\\n'\n",
      "                 '**Why the absurdity lands**\\n'\n",
      "                 '\\n'\n",
      "                 'Humor thrives on the unexpected. We’re primed for a quick '\n",
      "                 'laugh. The joke flips that expectation by giving us a '\n",
      "                 '*massive* laugh—literally a whole story. The exaggeration is '\n",
      "                 'so extreme that it feels like a satire of AI’s tendency to '\n",
      "                 'produce verbose,',\n",
      " 'joke': 'Large language models are so good at answering questions that when '\n",
      "         'you ask them for a joke, they keep rewriting the punchline until it '\n",
      "         'becomes a novella.',\n",
      " 'topic': 'large language models'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "config = {'configurable': {'thread_id': 1}}\n",
    "joke = workflow.invoke({'topic':'large language models'}, config=config)\n",
    "pprint(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990e5b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.', 'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-8210-6c9c-8002-0ffb369120eb'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:14:16.630372+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f591a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.', 'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-8210-6c9c-8002-0ffb369120eb'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:14:16.630372+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:14:14.477886+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, tasks=(PregelTask(id='c4983a25-9cd8-e7ef-af36-f1452281f311', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:14:13.407716+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='059bbba1-7239-e972-b806-280646f51abb', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-29T12:14:13.403619+00:00', parent_config=None, tasks=(PregelTask(id='1a5915e4-c5ef-db45-4419-a37315f37dd5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'large language models'}),), interrupts=())]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intermediate states\n",
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "499f6773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pasta',\n",
       " 'joke': '',\n",
       " 'explaination': 'Sure! Could you let me know which joke you’d like an explanation for? Once I have the joke, I can break it down and explain why it’s funny.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "workflow.invoke({'topic':'pasta'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3fef60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pasta', 'joke': '', 'explaination': 'Sure! Could you let me know which joke you’d like an explanation for? Once I have the joke, I can break it down and explain why it’s funny.'}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-5790-6911-8002-865faa2af740'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:23:35.888264+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-54eb-62c1-8001-b090da7bf566'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f9bb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5644bcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pasta', 'joke': '', 'explaination': 'Sure! Could you let me know which joke you’d like an explanation for? Once I have the joke, I can break it down and explain why it’s funny.'}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-5790-6911-8002-865faa2af740'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:23:35.888264+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-54eb-62c1-8001-b090da7bf566'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pasta', 'joke': ''}, next=('generate_explaination',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-54eb-62c1-8001-b090da7bf566'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:23:35.610829+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-3fde-6df4-8000-6b9f4cf9393d'}}, tasks=(PregelTask(id='3764cd97-dd0e-4f10-d2fa-f864bb3b9fc6', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': 'Sure! Could you let me know which joke you’d like an explanation for? Once I have the joke, I can break it down and explain why it’s funny.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pasta'}, next=('generate_joke',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-3fde-6df4-8000-6b9f4cf9393d'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:23:33.403783+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-3fd0-65f6-bfff-6905ed80fc69'}}, tasks=(PregelTask(id='0ad8c15e-8c56-0f7d-0cd7-0ffdd72efe2b', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': ''}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0d5-3fd0-65f6-bfff-6905ed80fc69'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-29T12:23:33.397852+00:00', parent_config=None, tasks=(PregelTask(id='890767d1-3e31-d99b-0b71-dc3198050cd0', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pasta'}),), interrupts=())]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7557c188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-29T12:14:13.403619+00:00', parent_config=None, tasks=(PregelTask(id='1a5915e4-c5ef-db45-4419-a37315f37dd5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'large language models'}),), interrupts=())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f0fd0c0-634a-6fa6-bfff-4702fee9ef85\"}}) ## checkpoint id from pizza run where we haver the topic but we need to generate the joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4180e4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'large language models',\n",
       " 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.',\n",
       " 'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f0fd0c0-634a-6fa6-bfff-4702fee9ef85\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5a18b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'large language models', 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.', 'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e4-0967-6f6a-8002-5071e14e9273'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:30:10.345927+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-fd23-6b19-8001-54b899cf5446'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-fd23-6b19-8001-54b899cf5446'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:30:09.059667+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-e953-6e1f-8000-6632e9ef7eaf'}}, tasks=(PregelTask(id='9b77535a-668e-02b8-6a4e-f69440b35484', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-e953-6e1f-8000-6632e9ef7eaf'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:30:06.982275+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='f9dc4221-d78c-a2e8-6445-9758c3a38130', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.', 'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-8210-6c9c-8002-0ffb369120eb'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:14:16.630372+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:14:14.477886+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, tasks=(PregelTask(id='c4983a25-9cd8-e7ef-af36-f1452281f311', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:14:13.407716+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='059bbba1-7239-e972-b806-280646f51abb', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-29T12:14:13.403619+00:00', parent_config=None, tasks=(PregelTask(id='1a5915e4-c5ef-db45-4419-a37315f37dd5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'large language models'}),), interrupts=())]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f62af907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0fd0e5-caf3-693f-8000-00d09976b305'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f0fd0c0-634a-6fa6-bfff-4702fee9ef85\", \"checkpoint_ns\": \"\"}}, {'topic':'Burger'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3587ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'Burger'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e5-caf3-693f-8000-00d09976b305'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:30:57.484199+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='83f684f2-937f-532c-9cd9-0a328e0424db', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.', 'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e4-0967-6f6a-8002-5071e14e9273'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:30:10.345927+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-fd23-6b19-8001-54b899cf5446'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-fd23-6b19-8001-54b899cf5446'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:30:09.059667+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-e953-6e1f-8000-6632e9ef7eaf'}}, tasks=(PregelTask(id='9b77535a-668e-02b8-6a4e-f69440b35484', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-e953-6e1f-8000-6632e9ef7eaf'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:30:06.982275+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='f9dc4221-d78c-a2e8-6445-9758c3a38130', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.', 'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-8210-6c9c-8002-0ffb369120eb'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:14:16.630372+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:14:14.477886+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, tasks=(PregelTask(id='c4983a25-9cd8-e7ef-af36-f1452281f311', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:14:13.407716+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='059bbba1-7239-e972-b806-280646f51abb', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-29T12:14:13.403619+00:00', parent_config=None, tasks=(PregelTask(id='1a5915e4-c5ef-db45-4419-a37315f37dd5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'large language models'}),), interrupts=())]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cd7c07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'large language models',\n",
       " 'joke': 'Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.',\n",
       " 'explaination': '**What the joke is saying**\\n\\n> “Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.”\\n\\nIt’s a *meta‑joke*—a joke that talks about itself (or about the process of making jokes).  \\nThe humor comes from a few intertwined layers:\\n\\n| Layer | What it is | Why it’s funny |\\n|-------|------------|----------------|\\n| **Setup** | “Large language models can write a 1,000‑word essay about a joke.” | It exaggerates a known fact: LLMs (like ChatGPT) can produce long, detailed text. The idea that a joke could be turned into a *thousand‑word essay* is absurd, because jokes are usually short and punchy. |\\n| **Punchline** | “and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.” | The punchline is a self‑referential twist. It claims that the LLM *forgets* the very thing that makes the joke funny. The humor is that the “forgetting” is caused by the LLM’s own tendency to keep producing more words—so it’s literally “too busy” to keep track of the punchline. |\\n| **Meta‑humor** | The joke is about an LLM writing a joke about an LLM. | This recursion (a joke about a joke about an LLM) is a classic form of meta‑humor that plays with expectations. The audience knows that the joke is “about the process of making jokes,” and the punchline is literally the process itself. |\\n| **Exaggeration** | “1,000‑word essay” + “forget the punchline” | Hyperbole is a staple of comedy. Saying an LLM can produce a *thousand‑word essay* is a comedic exaggeration of its output capacity. Saying it *forgets the punchline* is an equally exaggerated claim that a machine can lose focus on the core of humor. |\\n| **Self‑deprecation** | The LLM is portrayed as “too busy” and “forgetful.” | This pokes fun at the AI’s own limitations—while it can generate massive amounts of text, it doesn’t “remember” in the human sense. It’s a gentle ribbing of the technology’s tendency to over‑generate. |\\n\\n**Why the joke works**\\n\\n1. **Expectation vs. Reality**  \\n   The setup makes you think the joke will deliver a clever, witty punchline about LLMs. Instead'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f0fd0c0-634a-6fa6-bfff-4702fee9ef85\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6995d093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.', 'explaination': '**What the joke is saying**\\n\\n> “Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.”\\n\\nIt’s a *meta‑joke*—a joke that talks about itself (or about the process of making jokes).  \\nThe humor comes from a few intertwined layers:\\n\\n| Layer | What it is | Why it’s funny |\\n|-------|------------|----------------|\\n| **Setup** | “Large language models can write a 1,000‑word essay about a joke.” | It exaggerates a known fact: LLMs (like ChatGPT) can produce long, detailed text. The idea that a joke could be turned into a *thousand‑word essay* is absurd, because jokes are usually short and punchy. |\\n| **Punchline** | “and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.” | The punchline is a self‑referential twist. It claims that the LLM *forgets* the very thing that makes the joke funny. The humor is that the “forgetting” is caused by the LLM’s own tendency to keep producing more words—so it’s literally “too busy” to keep track of the punchline. |\\n| **Meta‑humor** | The joke is about an LLM writing a joke about an LLM. | This recursion (a joke about a joke about an LLM) is a classic form of meta‑humor that plays with expectations. The audience knows that the joke is “about the process of making jokes,” and the punchline is literally the process itself. |\\n| **Exaggeration** | “1,000‑word essay” + “forget the punchline” | Hyperbole is a staple of comedy. Saying an LLM can produce a *thousand‑word essay* is a comedic exaggeration of its output capacity. Saying it *forgets the punchline* is an equally exaggerated claim that a machine can lose focus on the core of humor. |\\n| **Self‑deprecation** | The LLM is portrayed as “too busy” and “forgetful.” | This pokes fun at the AI’s own limitations—while it can generate massive amounts of text, it doesn’t “remember” in the human sense. It’s a gentle ribbing of the technology’s tendency to over‑generate. |\\n\\n**Why the joke works**\\n\\n1. **Expectation vs. Reality**  \\n   The setup makes you think the joke will deliver a clever, witty punchline about LLMs. Instead'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e7-c271-6591-8002-48df0295f601'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:31:50.279059+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e7-adf0-6953-8001-7ddb55640b03'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e7-adf0-6953-8001-7ddb55640b03'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:31:48.129188+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e7-a84b-65e0-8000-265f2bc591a1'}}, tasks=(PregelTask(id='1cc4293d-8517-b9b1-d3e2-e632a945b7d5', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**What the joke is saying**\\n\\n> “Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.”\\n\\nIt’s a *meta‑joke*—a joke that talks about itself (or about the process of making jokes).  \\nThe humor comes from a few intertwined layers:\\n\\n| Layer | What it is | Why it’s funny |\\n|-------|------------|----------------|\\n| **Setup** | “Large language models can write a 1,000‑word essay about a joke.” | It exaggerates a known fact: LLMs (like ChatGPT) can produce long, detailed text. The idea that a joke could be turned into a *thousand‑word essay* is absurd, because jokes are usually short and punchy. |\\n| **Punchline** | “and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.” | The punchline is a self‑referential twist. It claims that the LLM *forgets* the very thing that makes the joke funny. The humor is that the “forgetting” is caused by the LLM’s own tendency to keep producing more words—so it’s literally “too busy” to keep track of the punchline. |\\n| **Meta‑humor** | The joke is about an LLM writing a joke about an LLM. | This recursion (a joke about a joke about an LLM) is a classic form of meta‑humor that plays with expectations. The audience knows that the joke is “about the process of making jokes,” and the punchline is literally the process itself. |\\n| **Exaggeration** | “1,000‑word essay” + “forget the punchline” | Hyperbole is a staple of comedy. Saying an LLM can produce a *thousand‑word essay* is a comedic exaggeration of its output capacity. Saying it *forgets the punchline* is an equally exaggerated claim that a machine can lose focus on the core of humor. |\\n| **Self‑deprecation** | The LLM is portrayed as “too busy” and “forgetful.” | This pokes fun at the AI’s own limitations—while it can generate massive amounts of text, it doesn’t “remember” in the human sense. It’s a gentle ribbing of the technology’s tendency to over‑generate. |\\n\\n**Why the joke works**\\n\\n1. **Expectation vs. Reality**  \\n   The setup makes you think the joke will deliver a clever, witty punchline about LLMs. Instead'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e7-a84b-65e0-8000-265f2bc591a1'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:31:47.537230+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='145b133b-6237-4ad8-7f26-bbef810f7ea6', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Large language models are the only thing that can write a 1,000‑word essay about a joke and still forget the punchline—because it’s too busy generating more content to remember what it was supposed to be funny about.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Burger'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e5-caf3-693f-8000-00d09976b305'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:30:57.484199+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='83f684f2-937f-532c-9cd9-0a328e0424db', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.', 'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e4-0967-6f6a-8002-5071e14e9273'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:30:10.345927+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-fd23-6b19-8001-54b899cf5446'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-fd23-6b19-8001-54b899cf5446'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:30:09.059667+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-e953-6e1f-8000-6632e9ef7eaf'}}, tasks=(PregelTask(id='9b77535a-668e-02b8-6a4e-f69440b35484', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**Why the “joke‑about‑itself” turned into a 2,000‑word essay + polite apology is funny**\\n\\n| Element | What happened | Why it’s humorous |\\n|---------|---------------|-------------------|\\n| **Expectation vs. delivery** | You asked for a *joke*—a quick, punchy line. The LLM gave a *long, academic* essay. | The classic “anti‑joke” setup: the audience is primed for a quick laugh, but the response is a marathon. The sheer mismatch is the first punchline. |\\n| **Meta‑self‑reference** | The essay is *about* humor, and it *mentions* the LLM itself. | Self‑referential humor is a staple of “meta‑comedy.” The AI is talking about its own difficulty in being funny, so it’s literally a joke about a joke‑making machine. |\\n| **Self‑deprecation** | The LLM apologizes for being too verbose. | Self‑deprecation is a safe, relatable form of humor. The AI, usually seen as efficient, now admits it’s “too wordy,” which feels oddly human and endearing. |\\n| **Exaggeration** | 2,000 words is *exaggerated* for a joke. | Exaggeration is a core comedic device. The LLM takes the minimal requirement (“a joke”) to an absurd extreme, making the result laugh‑worthy. |\\n| **Irony** | The AI’s explanation *is* the joke. | Irony arises when the outcome is the opposite of what is expected. The “joke” is an essay, but the essay itself explains why a joke is hard—so the joke *is* the explanation. |\\n| **Social cue** | Polite apology. | Politeness signals a social awareness that humans find charming. It’s an “I’m sorry” from a machine, which is a novelty. |\\n\\n### Step‑by‑step breakdown\\n\\n1. **The prompt**  \\n   *“Write a joke about yourself.”*  \\n   The audience’s mental model: “A snappy line about the LLM’s quirks, maybe a pun on ‘I’m not human but I can still be funny.’”\\n\\n2. **The LLM’s internal “analysis”**  \\n   - It recognizes that humor is subjective and hard to model.  \\n   - It decides to “explain” the difficulty—because that’s what it can do well (analysis, essay writing).  \\n   - It writes a 2,000‑word essay, covering theories of humor, AI’s limitations, and meta‑commentary on its own performance.\\n\\n3. **The punchline**  \\n   The essay ends with: *“I apologize for being too verbose.”*  \\n   The punchline is *the apology*—the unexpected, human‑like moment that breaks the narrative.\\n\\n4. **Why the audience laughs**  \\n   - **Cognitive dissonance**: The brain expects a short joke, gets a long essay → a humorous clash.  \\n   - **Relatability**: Everyone has been “too verbose” at some point.  \\n   - **Novelty**: An AI, a machine, apologizing for being verbose is a new, absurd concept.  \\n   - **Self‑reference**: The joke is about the joke‑maker, so it loops back on itself—funny because it’s a joke about a joke.\\n\\n### A quick comedic lens\\n\\n- **Setup**: “I asked my LLM to write a joke about itself.”  \\n- **Punchline**: “It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.”  \\n  The punchline is the *contrast* and the *apology*. The setup primes you for a one‑liner; the punchline delivers an entire essay + a human‑like apology—an absurd, self‑aware twist.\\n\\n### Bottom line\\n\\nThe humor comes from **mismatch + meta‑self‑reference + self‑deprecation**. The LLM’s “joke” is a joke about how difficult it is to joke, and the polite apology is the ultimate comedic twist that turns an academic essay into a laugh‑inducing moment. The joke works because it plays with our expectations, uses classic comedic devices, and gives an AI a moment of human‑like vulnerability.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0e3-e953-6e1f-8000-6632e9ef7eaf'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:30:06.982275+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='f9dc4221-d78c-a2e8-6445-9758c3a38130', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'I asked my LLM to write a joke about itself. It sent me a 2,000‑word essay on why humor is hard, then politely apologized for being too verbose.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.', 'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-8210-6c9c-8002-0ffb369120eb'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-01-29T12:14:16.630372+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models', 'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}, next=('generate_explaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6d89-6c1e-8001-6d200d33a3fe'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-01-29T12:14:14.477886+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, tasks=(PregelTask(id='c4983a25-9cd8-e7ef-af36-f1452281f311', name='generate_explaination', path=('__pregel_pull', 'generate_explaination'), error=None, interrupts=(), state=None, result={'explaination': '**What the joke is doing**\\n\\n- **Setup:** “Large language models are so good at answering questions …”  \\n  This tells the listener that the AI will give a perfect, thorough answer.\\n\\n- **Punchline (the twist):** “…when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.”  \\n  The expectation is a quick, one‑line punchline. Instead, the AI “rewrites” it over and over, turning a simple joke into a long, detailed story—literally a novella.\\n\\n**Why that’s funny**\\n\\n| Humor device | How it shows up in the joke |\\n|---------------|-----------------------------|\\n| **Incongruity** | A punchline is supposed to be short; the AI turns it into a long novel. |\\n| **Exaggeration** | The AI’s rewriting is taken to the extreme—so long it’s a novella. |\\n| **Meta‑humor** | The joke itself is about the process of making jokes, and it comments on the AI’s own behavior. |\\n| **Self‑referentiality** | The punchline is a “punchline” that is being rewritten, so the joke talks about itself. |\\n| **Commentary on AI** | It pokes fun at how LLMs can over‑explain or generate overly verbose responses. |\\n\\n**What’s happening in the story of the joke**\\n\\n1. **You ask the LLM for a joke.**  \\n   The LLM starts with a standard, concise answer.\\n\\n2. **The LLM “rewrites” the punchline.**  \\n   It refines, elaborates, adds details—just like an editor polishing a manuscript.\\n\\n3. **The process repeats.**  \\n   Each rewrite adds more depth, turning the one‑liner into a narrative arc.\\n\\n4. **Result:** a “novella” – a story that’s 20–40\\u202fk words long, far beyond what a joke needs.\\n\\n**Why the absurdity lands**\\n\\nHumor thrives on the unexpected. We’re primed for a quick laugh. The joke flips that expectation by giving us a *massive* laugh—literally a whole story. The exaggeration is so extreme that it feels like a satire of AI’s tendency to produce verbose,'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'large language models'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-6354-6ff3-8000-9d6d600d5c9f'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-29T12:14:13.407716+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, tasks=(PregelTask(id='059bbba1-7239-e972-b806-280646f51abb', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Large language models are so good at answering questions that when you ask them for a joke, they keep rewriting the punchline until it becomes a novella.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0fd0c0-634a-6fa6-bfff-4702fee9ef85'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-01-29T12:14:13.403619+00:00', parent_config=None, tasks=(PregelTask(id='1a5915e4-c5ef-db45-4419-a37315f37dd5', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'large language models'}),), interrupts=())]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe0da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
